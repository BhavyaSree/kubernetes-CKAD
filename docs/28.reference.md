---
title: Reference
---

### Persistent volumes and persistent volume claims

To inorder to bind pvc with a pv, accessMode and storageClassName of both should be same.

PV:
```yaml
spec:
 hostPath:  
   path:    
```

## PODS

## labels

show all the labels of pods   
`kubectl get pods --show-labels`  

Change the labels of pod 'nginx' to be app=v2  
`kubectl label pod nginx app=v2 --overwrite`  

Get the label 'app' for the pods  
`kubectl get pods --label-columns=app`   

Get only the 'app=v2' pods    
`kubectl get pods --selector=app=v2`  

Remove the 'app' label from the nginx pod  
`kubectl label pod nginx app-`  

Create a pod that will be deployed to a Node that has the label 'accelerator=nvidia-tesla-p100'  
`First add the label to the node`  
`kubectl label node <nodename> accelerator=nvidia-tesla-p100`   
`use the 'nodeSelector' property on the Pod YAML. under nodeSElector give the label.`  

To know where to write nodeSelector in the yaml file.   
`kubectl explain po.spec`  

Annotate pod nginx with "description='my description'" value  
`kubectl annotate pod nginx description='my description'`  

check the annotations for pod nginx  
`kubectl describe pod nginx | grep -i 'annotations'`  

remove the annotation  
`kubectl annotate pod description-`  

check how the deployment rollout is going  
`kubectl rollout status deploy <deploymentname>`  

check the rollout history  
`kubectl rollout history deploy <deploymentname>`  

undo the latest rollout   
`kubectl rollout undo deploy <deploymentname>`  

Return the deployment to the second revision (number 2)  
`kubectl rollout undo deploy <deploymentname> --to-revision=2`  

Check the details of the fourth revision   
`kubectl rollout history deploy <deploymentname>  --revision=4`  

Autoscale the deployment, pods between 5 and 10, targetting CPU utilization at 80%   
`kubectl autoscale deploy <deploymentname> --min=5 --max=10 --cpu-percent=80`  

pause the rollout of the deployment  
`kubectl rollout pause deploy <deploymentname>`  

Create Horzontal pod autoscaler for deployment nginx that maintains between 1 and 10 replicas of the Pods, targetting CPU utilization at 80%  
`kubectl autoscale deploy nginx --min=1 --max=10 --cpu-percent=80`  

Delete the deployment and the horizontal pod autoscaler you created  
`kubectl delete deploy nginx`  
`kubectl delete hpa nginx`  
or  
`kubectl delete deploy/nginx hpa/nginx`  

Create a job with image perl  
`kubectl create job pi --image=perl`   

Create a job with image perl that runs the command with arguments "perl -Mbignum=bpi -wle 'print bpi(2000)'"    
`kubectl create job pi  --image=perl -- perl -Mbignum=bpi -wle 'print bpi(2000)'`  

Create a job but ensure that it will be automatically terminated by kubernetes if it takes more than 30 seconds to execute  
`kubectl create job busybox --image=busybox --dry-run=client -o yaml -- /bin/sh -c 'while true; do echo hello; sleep 10; done'`  
Add activeDeadlineSeconds=30 under job spec section in yaml file and create the job.  


## configmaps

from literals  
`kubectl create cm map1 --from-literal=var1=val1`  

from file  
`echo -e 'var1=val1\nvar2=val2' > config.txt`   
`kuebctl create cm map2 --from-file=config.txt`  

from env file   
`echo -e 'var1=val1\nvar2=val2' > config.env`   
`kuebctl create cm map3 --from-file=config.env`  

from a file, giving the key special  
`kubectl create cm map4 --from-file=special=config.txt`  

Create a configMap called 'options' with the value var5=val5. Create a new nginx pod that loads the value from variable 'var5' in an env variable called 'option'  
`kubectl create cm options --from-literal=var5=val5`  
`kubectl run nginx --image=nginx --dry-run=client -o yaml > pod.yaml`  
Add 
```yaml
env:
 - name: option
   valueFrom:
      configMapkeyRef:
        name: options  
        key: var5
```
under spec.containers  

## Secrets

Create a secret with the values password=mypass  
`kubectl create secret generic mysecret --from-literal=password=mypass`  

from file  
`kubectl create secret generic mysecret --from-file=finename`  

To get the value of the secret  
`echo <data.username> | base64 -D`   


## PODS

### Create an nginx pod and list the pod with different levels of verbosity

`kubectl run nginx --image=nginx`    
`kubectl get pod nginx --v=7`  
`kubectl get pod nginx --v=8`  

### List the nginx pod with custom columns POD_NAME and POD_STATUS

`kubectl get pod nginx -o yaml | less`    
`kubectl get po -o=custom-columns="POD_NAME:.metadata.name, POD_STATUS:.status.containerStatuses[].state"`   

### List all the pods sorted by name

`kubectl get pods --sort-by=.metadata.name`   

### List all the pods sorted by created timestamp

`kubectl get pod nginx -o yaml | less`

### Output the yaml file of the pod you just created without the cluster-specific information

`kubectl get po nginx -o yaml --export > 1.yaml`  

### Create a Pod with three busy box containers with commands “ls; sleep 3600;”, “echo Hello World; sleep 3600;” and “echo this is the third container; sleep 3600” respectively and check the status

`kubectl run busybox1 --image=busybox --dry-run=client -o yaml -- /bin/sh -c "ls; sleep 3600" > multi.yaml`  
Edit the file and add remaining containers
`kubectl create -f multi.yaml`  

To check it's logs  
`kubectl logs busybox1 -c <containername>`  

### Run command ls in the third container busybox3 of the above pod  

`kubectl exec busybox -c busybox3 -- /bin/sh -c 'ls'` or  
`kubectl exec busybox -c busybox3 -- ls`  

### Show metrics of the above pod containers and puts them into the file.log and verify  

`kubectl top pod busybox --containers`  
but this is not working with error get services http:heapster  
Have to check on this  

### Create a Pod with main container busybox and which executes this “while true; do echo ‘Hi I am from Main container’ >> /var/log/index.html; sleep 5; done” and with sidecar container with nginx image which exposes on port 80. Use emptyDir Volume and mount this volume on path /var/log for busybox and on path /usr/share/nginx/html for nginx container. Verify both containers are running.  

We can create a pod using imeprative command and add conatiners and volumes to the yaml file and then create multi-container pod using yaml file..

### Exec into both containers and verify that index.html exist and query the index.html from sidecar container with curl localhost   

`kubectl exec -it multi-container-pod -c main-con -- /bin/sh -c 'cat /var/log/index.html'`  

`kubectl exec -it multi-container-pod -c sidecar-con -- /bin/sh -c 'cat /usr/share/nginx/html/index.html'`  

with localhost  
`kubectl exec -it multi-container-pod -c sidecar-con -- /bin/sh`  
`# apt-get update && apt-get install -y curl`    
`# curl localhost`  

## Pod Design (20%)

### Get the pods with label information

`kubectl get pods --show-labels`  

### labelling(env=dev) the pod using imperative command  

`kubectl run nginx --image=busybox --labels=env=dev`   

### Get the pods with label env=dev  

`kubectl get pods -l env=dev`  

### Get the pods with label env=dev and also output the labels

`kubectl get pods -l env=dev --show-labels`  

### Get the pods with label env  

`kubectl get pods -L env`  

### Get the pods with labels env=dev and env=prod  

`kubectl get pods -l 'env in (dev,prod)'`  

### change the label for the pod  

`kubectl label pod nginx env=uat --overwrite`  

### remove the labels for the pod  

`kubectl label pod nginx env-`  

### Add the label for the pod  

`kubectl label pod nginx env=dev`  

### To label the node  

`kubectl label node <nodename> <label>`  
same as for pod  

Eg: Label the node (minikube if you are using) nodeName=nginxnode  

`kubectl label node minikube nodeName=nginxnode`  

### Create a Pod that will be deployed on this node with the label nodeName=nginxnode  

`kubectl run nginx --image=nginx --dry-run=client -o yaml > pod.yaml`    

Add  
```yaml
nodeSelector:
  nodeName=nginxnode 
``` 
under spec section in yaml file  

`kubectl create -f pod.yaml`  

### Verify the pod that it is scheduled with the node selector  

`kubectl describe po nginx | grep Node-Selectors`  

### Annotate the pods with name=webapp  

`kubectl annotate pod nginx name=webapp`  

### Get the pods of this deployment

First check the labels of the deployment  
`kubectl get deployment <name> --show-labels`    

As the labels of deployment and pods in that will be same  
`kubectl get pods -l <labels>`   

### Get the deployment rollout status  

`kubectl rollout status deployment webapp`    

### Get the replicaset that created with the deployment

First we need to know th labels of the deployment and use them to get the rs.
`kubectl get rs -l <labels>`  

### to watch any action   

use `-w` option at the end of the command  

### Check the rollout history 

`kubectl rollout history deployment <name>`  

### undo the deployment to previous version  

`kubectl rollout undo deployment <name>`   

### To record the changes of the deployment for example changing image

`kubectl set image deployment <name> <containername>=<newimage> --record`  

### undo the deployment to a particular previous versio 

`kubectl rollout undo deployment <name> --to-revision=<number>`   

### Check the history of the specific revision of that deployment

`kubectl rollout history deployment <name>  --revision=<number>`  

### Pause the rollout of the deployment

`kubectl rollout pause deployment <name>`  

### Resume the rollout of the deployment  

`kubectl rollout resume deployment <name>`  

When we make any changes to the deployment after pausing the rollout, the changes will be done in the deployment but the revision cannot be seen in the rollout history.  
After resuming the rollout, we can see the revisions of changes done in the rollout history.  

### Apply the autoscaling to this deployment with minimum 10 and maximum 20 replicas and target CPU of 85% and verify hpa is created and replicas are increased to 10 from 1

`kubectl autoscale deployment <name> --min=10 --max=20 --cpu-percent=85`  
`kubectl get hpa`  
`kubectl get pods -l <deployment labels>`  












